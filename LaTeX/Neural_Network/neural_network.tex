%% sudo yum install tetex
%% sudo yum install texlive-elsarticle.noarch
%% pdflatex neural_network.tex && bibtex neural_network.aux && pdflatex neural_network.tex && pdflatex neural_network.tex


%\documentclass[a4paper,12pt]{}
\documentclass[final, paper=letter,5p,times,twocolumn]{elsarticle}
%\documentclass[preprint,review,8pt,times]{elsarticle}


%% or use the graphicx package for more complicated commands
%\usepackage{changebar}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{tikz}
\usepackage{amsmath,amsfonts,amsthm,multicol,bm} % Math packages
%\usepackage{dsfont} % mathds{1}
%\usepackage{widetext} % 
\usepackage{listings}
\usepackage{amssymb}
\usepackage{hyperref}
%
%\usepackage[]{algorithm2e}
%% Macro
\newcommand{\ToDo}[1]{ToDo: \textbf{\textit{#1}}}
\newcommand{\CA}{computational anatomy}
%
\newdefinition{definition}{Definition}%
\newtheorem{theorem}{Theorem}%
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
%\newproposition{proposition}{Proposition}%
%\newlemma{lemma}{Lemma}%
%\AtEndEnvironment{theorem}{\null\hfill\qedsymbol}%

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frontmatter}

\title{Neural network}

\author[label1]{Yann Cobigo\corref{cor1}}
\address[label1]{University of California, San Francisco | ucsf.edu}
%\address[label2]{Address Two\fnref{label4}}

%\cortext[cor1]{I am corresponding author}
%\fntext[label3]{I also want to inform about\ldots}
%\fntext[label4]{Small city}

\ead{yann.cobigo@ucsf.edu}
\ead[url]{https://github.com/YannCobigo}

%% \author[label5]{Author Two}
%% \address[label5]{Some University}
%% \ead{author.two@mail.com}
%% 
%% \author[label1,label5]{Author Three}
%% \ead{author.three@mail.com}

\begin{abstract}
In this report we will \dots
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Fijee \sep electrode \sep PEM \sep CEM
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\end{keyword}

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

\paragraph{Inputs}{For the different type of neural networks we would like to accomplish, the input classes must be very differents. Most of the time we are going to work with medical images, implying using a dimensional correlation like the convolutional neural network (CNN). Unlike most of the machine learning algorithm taking vectors as input, CNN void the space decorrelation from the vectorization. However, providing different calsses for different inputs could offer some flexibility.}

\ToDo{check ll sort of input we would want.} \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Functions}

A neuron is represented with an activation $a_{l_{i}} = \sum_{l_{j} = 0}^{L_{j}} \omega_{l_{i}l_{j}} z_{l_{j}}$, integrating pulses from from other neurons, and its activation function $z_{l_{i}} = f(a_{l_{i}})$, the firering process of the neuron. Usually, the activation function is taken non-linear.

\subsection{Activation functions}

\subsubsection{Soft maximum}
\label{soft_max_sec}

The soft maximum is often used in classfication problem involving multiple output classes. the output can be interpretated as probability following the distribution:

\begin{equation}
  g(a_{l_{k}}) = \frac{e^{a_{l_{k}}}}{\mathcal{Z}}
  \label{soft_max}
\end{equation}

Where $\mathcal{Z}$ is the partition function normalizing the distribution. Derivating the soft maximum in function of the distrit parameter $a_{k}$ gives us:

  \begin{equation*}
    \begin{split}
      \frac{\partial g(a_{k})}{\partial a_{k'}} = & \left \lbrack \delta_{kk'} e^{a_{k'}} \mathcal{Z} - e^{a_{k'}}\frac{\partial \mathcal{Z}}{\partial a_{k'}} \right \rbrack \times \frac{1}{\mathcal{Z}^{2}}\\
      = & \left \lbrack \delta_{kk'} e^{a_{k'}} \mathcal{Z} - e^{a_{k'}} \sum_{k''} \delta_{kk''} e^{a_{k''}}  \right \rbrack \times \frac{1}{\mathcal{Z}^{2}}\\
      = & \frac{\delta_{kk'} e^{a_{k'}}}{\mathcal{Z}} - z_{k}z_{k'}\\
    \end{split}
\end{equation*}


\subsection{Cost functions}

Training the neural network uses the gradient method. All functions representing the neural activity needs to be differentiable, including the cost fuction.

\subsubsection{Least-squarre cost function}

\begin{equation}
  E = \frac{1}{2} \sum_{i = 1}^{n} \| \bm{z}(\bm{x}_{i}) - \bm{t}_{i} \|^{2}
  \label{least_squarre}
\end{equation}

\subsubsection{Cross entropy cost function}
\label{Cross_entropy_cost_function_sec}

In information theory, the cross entropy between two probability distributions $p$ and $q$ over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an "unnatural" probability distribution $q$, rather than the "true" distribution $p$. In classification, the cross entropy for the distributions $t$, labels, and $z$, reconstructed solution, over a given set is defined as follows:

\begin{equation}
  E = - \sum_{i = 1}^{n}\sum_{l'_{k} = 1}^{L_{k}} t_{l'_{k}} \ln z_{l'_{k}} =  - \sum_{i = 1}^{n} E_{i}
  \label{cross_entropy}
\end{equation}

$t_{k}$ represents the known label, $z_{l'_{k}} = y_{k}$ represents the response of the system, $n$ is the number of participents. 

In this section, we are going to derivate the cross entropy~\ref{cross_entropy}. To simplify the equation, we are derivating the cost function only for one subject and omitte the subscript $i$. At the output layer, the activation is $a_{l_{k}} = \sum_{l_{k-1} = 0}^{L_{k-1}} \omega_{l_{k}l_{k-1}} z_{l_{k-1}}$. The derivative of the cost function in function of the activtion is called the {\it error} and is written:

\begin{equation}
  \delta_{k} = \frac{\partial E}{\partial a_{l_{k}}} = - \sum_{l'_{k} = 1}^{L_{k}} t_{l'_{k}} \times \frac{1}{z_{l'_{k}}} \frac{\partial z_{l'_{k}}}{\partial a_{k}}
  \label{cost_function_error}
\end{equation}

In the case of the last activation fuction for the output layer is a soft maximum, we can use the result of the soft maximum derivative from the paragraph~\ref{soft_max_sec}:

\begin{equation*}
  \begin{split}
    \delta_{k} = & - \sum_{l'_{k} = 1}^{L_{k}} t_{l'_{k}} \times \frac{1}{z_{l'_{k}}} \left \lbrack  \frac{\delta_{kk'} e^{a_{l'_{k}}}}{\mathcal{Z}} - z_{l'_{k}}z_{l_{k}} \right \rbrack \\
    = & - \sum_{l'_{k} = 1}^{L_{k}} t_{l'_{k}} \times \frac{1}{z_{l'_{k}}} \frac{\delta_{kk'} e^{a_{l'_{k}}}}{\mathcal{Z}} +  \sum_{l'_{k} = 1}^{L_{k}} t_{l'_{k}} z_{l_{k}} \\
    = & - t_{l_{k}} +  z_{k} \\
  \end{split}
\end{equation*}



Which is exactly the same result as we would get in the cas of a least-square cost function.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Densly connected neural network}
\subsection{Description and notation}

Dense neural networks are cracterized by a full connection of a neuron of one layer with all neurons from the previouse layer. Table~\ref{Layers_activations} presents the activation function for each layer. In this document, the convention is $l = l_{0}$ for the input layer: $z_{l_{0} = 1} = x_{1}$, $z_{l_{0} = 2} = x_{2}$, \dots we will reserve the index 0 for the bias: $z_{l_{0} = 0} = x_{0} = b_{0}$ the bias on the input level. The last level is the output level: $l = l_{k}$, $z_{l_{k}} = y_{k}$. The output level does not have a bias node.

\begin{table}[]
\centering
\caption{Neuron activation for each layers.}
\label{Layers_activations}
\begin{tabular}{llllll}
 $\{ z_{l_{0}}\}_{l_{0} = 0}^{L_{0}}$&  $\{ z_{l_{1}}\}_{l_{1} = 0}^{L_{1}}$ &  $\cdots$ & $\{ z_{l_{k-1}}\}_{l_{k-1} = 0}^{L_{k-1}}$ &  $\{ z_{l_{k}}\}_{l_{k} = 1}^{L_{k}}$ &  \\ 
\end{tabular}
\end{table}

Each neuron is an activated function, $f$, of a linear combinaison of the neurons from the previous layer. Function $g$ is the activation function for the output layer.

\begin{itemize}
    \item [$l = l_{0}$] we are at the level of the inputs
    \item [$l = l_{1}$] $a_{l_{1}} = \sum_{l'_{0} = 0}^{L_{0}} \omega_{l_{1}l'_{0}} z_{l'_{0}} = \omega_{l_{1}}^{T} z^{(0)}$. And $z_{l_{1}} = f(a_{l_{1}})$
    \item [$\vdots$]
    \item [$l = l_{k-1}$] $a_{l_{k-1}} = \sum_{l'_{k-2} = 0}^{L_{k-2}} \omega_{l_{k-1}l'_{k-2}} z_{l'_{k-2}} = \omega_{l_{k-1}}^{T} z^{(k-2)}$. And $z_{l_{k-1}} = f(a_{l_{k-1}})$
    \item [$l = l_{k}$] $a_{l_{k}} = \sum_{l'_{k-1} = 0}^{L_{k-1}} \omega_{l_{k}l'_{k-1}} z_{l'_{k-1}} = \omega_{l_{k}}^{T} z^{(k-1)}$. And $z_{l_{k}} = g(a_{l_{k}})$
\end{itemize}

In this enumeration $z^{(i)}$ is a vector of all neurons on the layer $(i)$. There are several choises for the activation function and we will try to provide the possibility of using several of them. However, the first developpments will be done with the hyperbolic tangent for the activation of the inside layers nerons: $f = \tanh$ and $f' = (1 - \tanh^{2})$. The last layer, the output layer, will be calculated with a soft maximum: $g(z_{l_{k}}) = e^{a_{l_{k}}} / \mathcal{Z}$, where the partition function $\mathcal{Z} = \sum_{l_{k} = 1}^{L_{k}} e^{z_{l_{k}}}$, and $g' = g(1 - g)$.
  
\subsection{Forward propagation}

The forward propagation is straight forward. For a solution, $y_{k} = z_{l_{k}} = g(a_{l_{k}})$ where
$$
a_{l_{k}} = \omega_{l_{k}}^{T} z^{(k-1)} = \omega_{l_{k}}^{T} f(\omega_{l_{k-1}}^{T} z^{(k-2)}) = \omega_{l_{k}}^{T} f(\omega_{l_{k-1}}^{T} f(\omega_{l_{k-2}}^{T} z^{(k-3)})) = \dots
$$

\subsubsection{Algorithm}

The Table~\ref{weights_distribution} guives the distribution of the weights in a dense neural network. Those weights can be represented in one long array in the hardware memory, Table~\ref{weights_in_mem}. The first layer $l = l_{1}$, after the inputs, has $(L_{1}+1)\times(L_{0}+1)$ weights. The layer after has $(L_{2}+1)\times(L_{1}+1)$ weights, so forth till the last layer having $L_{k}\times(L_{k-1}+1)$.

\begin{table}[]
\centering
\caption{Weight distribution per layer.}
\label{weights_distribution}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$l_{0}$                   && 0                                   & 1                        & $\cdots$ & $L_{0}$ \\ \hline
\multirow{4}{*}{$l_{1}$}  &0& $\omega_{l_{1}=0l_{0}=0}$              & $\omega_{l_{1}=0l_{0}=1}$    &        & $\omega_{l_{1}=0l_{0}=L_{0}}$ \\ \cline{2-6} 
                         &1& $\omega_{l_{1}=1l_{0}=0}$              & $\omega_{l_{1}=1l_{0}=1}$    &        & $\omega_{l_{1}=0l_{0}=L_{0}}$ \\ \cline{2-6} 
                         &&                                     &                          & \vdots & \\ \cline{2-6} 
                         &$L_{1}$& $\omega_{l_{1}=L_{1}l_{0}=0}$      & $\omega_{l_{1}=L_{1}l_{0}=1}$ &        & $\omega_{l_{1}=L_{1}l_{0}=L_{0}}$ \\ \hline
$l_{1}$                   && 0                                   & 1                       &        & $L_{1}$ \\ \hline
\multirow{4}{*}{$l_{2}$}  &0& $\omega_{l_{2}=0l_{1}=0}$              &  $\omega_{l_{2}=0l_{1}=1}$   &        &  $\omega_{l_{2}=0l_{1}=L_{1}}$ \\ \cline{2-6} 
                         &1& $\omega_{l_{2}=1l_{1}=0}$              &  $\omega_{l_{2}=1l_{1}=1}$   &        &   $\omega_{l_{2}=0l_{1}=L_{1}}$ \\ \cline{2-6} 
                         &&                                     &                          & \vdots & \\ \cline{2-6} 
                         &$L_{2}$&$\omega_{l_{2}=L_{2}l_{1}=0}$       & $\omega_{l_{2}=L_{2}l_{1}=1}$ &        & $\omega_{l_{2}=L_{2}l_{1}=L_{1}}$ \\ \hline
\vdots                   &&                                     &                         &        & \\ \hline
$l_{k-1}$                 && 0                                   &  1                      &        &  $L_{k-1}$ \\ \hline
\multirow{4}{*}{$l_{k}$}  &1& $\omega_{l_{k}=1l_{k-1}=0}$            & $\omega_{l_{k}=1l_{k-1}=1}$  &        & $\omega_{l_{k}=1l_{k-1}=L_{k-1}}$ \\ \cline{2-6} 
                         &2& $\omega_{l_{k}=2l_{k-1}=0}$            & $\omega_{l_{k}=2l_{k-1}=1}$  &        &  $\omega_{l_{k}=2l_{k-1}=L_{k-1}}$ \\ \cline{2-6} 
                         &&                                    &                         & \vdots & \\ \cline{2-6} 
                         &$L_{k}$& $\omega_{l_{k}=L_{k1}l_{k-1}=0}$   & $\omega_{l_{k}=L_{k}l_{k-1}=1}$ &        &  $\omega_{l_{k}=L_{k}l_{k-1}=L_{k-1}}$ \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Representation in a one dimension array of the all the weights.}
\label{weights_in_mem}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{$l_{1}$} & $\hdots$ & \multicolumn{3}{c|}{$l_{k}$} \\ \hline
$\omega_{l_{1}=0l_{0}=0}$   &   $\omega_{01}$   & $\hdots$  &  $\omega_{L_{1}L_{0}}$   & $\hdots$ &    $\omega_{l_{k}=1l_{k-1}=0}$    & $\hdots$  &   $\omega_{L_{k}L_{k-1}}$ \\ \hline
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Backward propagation}

To solve the problem of the backward propagation, we have three options. The first option is to estimate the error for the full training set, which is heavy for the algorithm. The second option is the gradient descent in its stochastic version: each iteration will use a new intput, instead of estimating the cost function with the entire input population. The third option is a mid point between the two first option: the error is estimated with a batches sub set of the full training set.
Taking the cross-enropy cost function, eq.~(\ref{cross_entropy}), in the case of classificaion. The gradiant descent can be evaluated in a classic way: taking all the participents for each iterations; or in a stochastic way: taking a new participent every iterations. The gradient descent method used to find the minimum of the cost function is written:

\begin{equation}
  \bm{\omega}^{e+1} = \bm{\omega}^{e} - \eta \bm{\nabla} E
  \label{gradient_descent}
\end{equation}

Where $\bm{\omega}$ represents the vector of weights, $e$ represents the {\it epoque}, and $\eta$ represents the learning rate. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Algorithm}

The backward propagation for each layer, except the last layer, is a recursive estimtion of the deeper layer. The gradient~(\ref{gradient_descent}) at a particular weight is

\begin{equation*}
  \frac{\partial E_{i}}{\partial \omega_{l_{u}l_{v}}} = \frac{\partial E_{i}}{\partial a_{l_{u}}} \frac{\partial a_{l_{u}}}{\partial \omega_{l_{u}l_{v}}} = \delta_{l_{u}}\frac{\partial a_{l_{u}}}{\partial \omega_{l_{u}l_{v}}} 
\end{equation*}


\paragraph{$\bm{l = l_{k}}$}{ Using the results from the section~\ref{Cross_entropy_cost_function_sec}:

  \begin{equation*}
    \begin{split}
      \frac{\partial E_{i}}{\partial \omega_{l_{k}l_{k-1}}} = &  \frac{\partial E_{i}}{\partial a_{l_{k}}} \frac{\partial a_{l_{k}}}{\partial \omega_{l_{k}l_{k-1}}}  \\
              = &  (z_{l_{k}} - t_{l_{k}})z_{l_{k-1}} \\
    \end{split}
  \end{equation*}

}

\paragraph{$\bm{l = l_{u}}$}{Using the chain rules of partial derivative, we found:

  \begin{equation*}
    \begin{split}
      \frac{\partial E_{i}}{\partial \omega_{l_{u}l_{u-1}}} = &  \frac{\partial E_{i}}{\partial a_{l_{u}}} \frac{\partial a_{l_{u}}}{\partial \omega_{l_{u}l_{u-1}}} = \delta_{l_{u}} \frac{\partial a_{l_{u}}}{\partial \omega_{l_{u}l_{u-1}}}  \\
              = & \sum_{l'_{u+1}}\frac{\partial E_{i}}{\partial a_{l'_{u+1}}} \frac{\partial a_{l'_{u+1}}}{\partial a_{l_{u}}} \frac{\partial a_{l_{u}}}{\partial \omega_{l_{u}l_{u-1}}}   \\
              = & \sum_{l'_{u+1}} \delta_{l'_{u+1}} \frac{\partial a_{l'_{u+1}}}{\partial a_{l_{u}}} z_{l_{u-1}}   \\
              = & \sum_{l'_{u+1}} \delta_{l'_{u+1}} \sum_{l'_{u}} \omega_{l'_{u+1}l'_{u}} f'(a_{l'_{u}}) \delta_{l'_{u}l_{u}} z_{l_{u-1}}   \\
              = & \sum_{l'_{u+1}} \delta_{l'_{u+1}} \omega_{l'_{u+1}l_{u}} f'(a_{l_{u}}) z_{l_{u-1}}   \\
    \end{split}
\end{equation*}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sect}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sect}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sect}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\section*{References}
%% References with bibTeX database:
\bibliographystyle{Bibliography/elsarticle-num}

\bibliography{Bibliography/sample}


\end{document}
