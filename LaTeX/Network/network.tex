%% sudo yum install tetex
%% sudo yum install texlive-elsarticle.noarch
%% pdflatex network.tex && bibtex network.aux && pdflatex network.tex && pdflatex network.tex


%\documentclass[a4paper,12pt]{}
\documentclass[final, paper=letter,5p,times,twocolumn]{elsarticle}
%\documentclass[preprint,review,8pt,times]{elsarticle}


%% or use the graphicx package for more complicated commands
%\usepackage{changebar}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{tikz}
\usepackage{amsmath,amsfonts,amsthm,multicol,bm} % Math packages
%\usepackage{dsfont} % mathds{1}
%\usepackage{widetext} % 
\usepackage{listings}
\usepackage{amssymb}
\usepackage{hyperref}
%
%\usepackage[]{algorithm2e}
%% Macro
\newcommand{\ToDo}[1]{ToDo: \textbf{\textit{#1}}}
\newcommand{\CA}{computational anatomy}
%
\newdefinition{definition}{Definition}%
\newtheorem{theorem}{Theorem}%
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
%\newproposition{proposition}{Proposition}%
%\newlemma{lemma}{Lemma}%
%\AtEndEnvironment{theorem}{\null\hfill\qedsymbol}%

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frontmatter}

\title{Structural connectivity network}

\author[label1]{Yann Cobigo\corref{cor1}}
\address[label1]{University of California, San Francisco | ucsf.edu}
%\address[label2]{Address Two\fnref{label4}}

%\cortext[cor1]{I am corresponding author}
%\fntext[label3]{I also want to inform about\ldots}
%\fntext[label4]{Small city}

\ead{yann.cobigo@ucsf.edu}
\ead[url]{https://github.com/YannCobigo}

%% \author[label5]{Author Two}
%% \address[label5]{Some University}
%% \ead{author.two@mail.com}
%% 
%% \author[label1,label5]{Author Three}
%% \ead{author.three@mail.com}

\begin{abstract}
In this report we will \dots
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Fijee \sep electrode \sep PEM \sep CEM
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\end{keyword}

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Attempts to characterize these datasets have, over the last decade, led to the emergence of a new, multidisciplinary approach to the study of complex systems. This approach, known as complex network analysis, describes important properties of complex systems by quantifying topologies of their respective network representations. Complex network analysis has its origins in the mathematical study of networks, known as graph theory. However, unlike classical graph theory, the analysis primarily deals with real-life networks that are large and complexâ€”neither uniformly random nor ordered.

\ToDo{Def. geodisic} \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Network measures of the brain connectivity}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Measures of functional segregation}

Functional segregation in the brain is the ability for specialized processing to occur within densely interconnected groups of brain regions. Measures of segregation primarily quantify the presence of such groups, known as clusters or modules, within the network. Measures of segregation have straightforward interpretations in anatomical and functional networks. The presence of clusters in anatomical networks suggests the potential for functional segregation in these networks, while the presence of clusters in functional networks suggests an organization of statistical dependencies indicative of segregated neural processing.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Finding community structure -- Newman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Measures of functional integration}

Functional integration in the brain is the ability to rapidly combine specialized information from distributed brain regions. Measures of integration characterize this concept by estimating the ease with which brain regions communicate and are commonly based on the concept of a path. Paths are sequences of distinct nodes and links and in anatomical networks represent potential routes of information flow between pairs of brain regions. Lengths of paths consequently estimate the potential for functional integration between brain regions, with shorter paths implying stronger potential for integration. On the other hand, functional connectivity data, by its nature, already contain such information for all pairs of brain regions. Paths in functional networks represent sequences of statistical associations and may not correspond to information flow on anatomical connections. Consequently, network measures based on functional paths are less straightforward to interpret. Such measures may be easier to interpret when information about anatomical connections is available for the same subjects.

\begin{definition}
  {\bf Characteristic path length $L$.} Here $L$ is defined as the number of edges in the shortest path between two vertices $i$ and $j$ along the geodesic $g_{i \leftrightarrow j}$, averaged over all pairs of vertices where:
  $$
  d_{ij} = \sum_{a_{uv} \in g_{i \leftrightarrow j}} a_{uv}
  $$

  And

  $$
  L = \frac{1}{n} \sum_{v \in N} L_{v} =  \frac{1}{n} \sum_{v \in N} \frac{\sum_{u \in N, u \ne v} d_{vu}}{n-1}
  $$
\end{definition}

\begin{definition}
  {\bf Clustering coefficient $C$.} Suppose that a vertex $v$ has $k_{v}$ neighbours; then at most $k_{v}(k_{v} -1)/2$ edges can exist between them (this occurs when every neighbour of $v$ is connected to every other neighbour of $v$). Let $C_{v}$ denote the fraction of these allowable edges that actually exist. Define $C$ as the average of $C_{v}$ over all $v$.

  $$
  C = \frac{1}{n} \sum_{v \in N} C_{i} = \frac{1}{n} \sum_{v \in N} t_{v} \times \frac{2}{k_{v}(k_{v} -1)}
  $$

  $t_{v}$ representes the number of edges that actually exist arround $v$.
\end{definition}

For friendship networks, these statistics have intuitive meanings: $L$ is the average number of friendships in the shortest chain connecting two people; $C_{v}$ reflects the extent to which friends of $v$ are also friends of each other; and thus $C$ measures the cliquishness of a typical friendship circle.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Small-worldness}

We quantify the structural properties of these graphs by their characteristic path length $L$ and clustering coefficient $C$. Here $L$ measures the typical separation between two vertices in the graph (a global property), whereas $C$ measures the {\it cliquishness} of a typical neighbourhood (a local property). The networks of interest to us have many vertices with sparse connections, but not so sparse that the graph is in danger of becoming disconnected. Specifically, we require $n \gg k \gg \ln(n) \gg 1$, where $k \gg \ln(n)$ guarantees that a random graph will be connected. In this regime, we find that $L \sim n/2k \gg 1$ and $C \sim 3/4$, while $L < L_{random} \sim \ln(n) / \ln(p)$ and $C < C_{random} \sim k/n \ll 1$. Thus the regular lattice is a highly clustered, large world where $L$ grows linearly with $n$, whereas the random network at is a poorly clustered, small world where $L$ grows only logarithmically with $n$. These limiting cases might lead one to suspect that large $C$ is always associated with large $L$, and small $C$ with small $L$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Assortativity}

A network is said to show assortative mixing if the nodes in the network that have many connections tend to be connected to other nodes with many connections. Within the framework of this model we find that assortative networks tend to percolate more easily than their disassortative counterparts and that they are also more robust to vertex removal. One particularly well-studied model is the cumulative advantage or preferential attachment model in which the probability of a given source vertex forming a connection to a target vertex is some (usually increasing) function of the degree of the target vertex. (The degree of a vertex is the number of other vertices to which it is attached.) Preferential attachment processes are widely accepted as the probable explanation for the power-law and other skewed degree distributions seen in many networks. However, there is an important element missing from these as well as other network models: in none of these models does the probability of attachment to the target vertex depend also on the degree of the source vertex. In the real world on the other hand such dependencies are common. Many networks show "assortative mixing" on their degrees, i.e., a preference for high-degree vertices to attach to other high-degree vertices. Others show disassortative mixing-high-degree vertices attach to low-degree ones.\\

%{Assortative mixing in networks, Newman}

$$
r = \frac{l^{-1} \sum_{(i,j) \in L} k_{i}k_{j} - \lbrack l^{-1} \sum_{(i,j) \in L} (k_{i} + k_{j})/2 \rbrack^{2}}{l^{-1} \sum_{(i,j) \in L} (k_{i}^{2} + k_{j}^{2})/2 - \lbrack l^{-1} \sum_{(i,j) \in L} (k_{i} + k_{j})/2 \rbrack^{2}}
$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sect}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sect}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sect}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\section*{References}
%% References with bibTeX database:
\bibliographystyle{Bibliography/elsarticle-num}

\bibliography{Bibliography/sample}


\end{document}
